%-------------------------------------------------------------------------------
\subsection{Feasibility and Convergence}

Under these considerations, we can now state the theorem that relates to
the guaranteeing of the stability of the compound system of agents
$i \in \mathcal{V}$, when each of them is assigned a desired
position which results in feasible displacements:\\

\begin{bw_box}
\begin{theorem}

  Suppose that

  \begin{enumerate}
    \item the terminal region $\mathcal{E}_i^f \subseteq \mathcal{E}_i$ is
      closed with $0 \in \mathcal{E}_i^f$
    \item a solution to the optimal control problem \eqref{position_based_cost} -
      \eqref{constraint:p_5} is feasible at time $t=0$, that is, assumptions
      \eqref{ass:measurements_access}, \eqref{ass:initial_conditions}, and
      \eqref{ass:after_formation_geometry} hold at time $t=0$
    \item there exists an admissible control input
      $\vect{u}_i^f : [0, h] \to \mathcal{U}_i$ such that for all
      $\vect{e}_i \in \mathcal{E}_i^f$ and $\tau \in [0,h]$:

      \begin{enumerate}
        \item $\vect{e}_i(\tau) \in \mathcal{E}_i^f$
        \item $\dfrac{\partial V_i}{\partial \vect{e}_i} g_i\big(\vect{e}_i(\tau), \vect{u}_i^f(\tau)\big)
          + F_i\big(\vect{e}_i(\tau), \vect{u}_i^f(\tau)\big) \leq 0$
      \end{enumerate}

  \end{enumerate}

  then the closed loop system \eqref{eq:position_based_error_model} under the
  control input \eqref{eq:position_based_optimal_u} converges to the set
  $\mathcal{E}_i^f$ when $t \to \infty$.

\end{theorem}
\end{bw_box}

\textbf{Proof}. The proof of the above theorem consists of two parts:
in the first, recursive feasibility is established, that is, initial
feasibility is shown to imply subsequent feasibility; in the second, and based
on the first part, it is shown that the error $\vect{e}_i(t)$ converges to the
terminal set $\mathcal{E}_i^f$.\\

\textbf{Feasibility analysis}
Consider a sampling instant $t_k$ for which a
solution $\vect{u}_i^{\star}\big(\cdot;\ \vect{e}_i(t_k)\big)$ to
\eqref{position_based_cost} exists.
%In between $t_k$ and $t_k + h$,
%where $h$ is the sampling time, the optimal control signal
%$\vect{u}_i^{\star}\big(\cdot;\ \vect{e}_i(t_k)\big)$ is applied to the open-loop
%system.
Suppose now a time instant $t_{k+1}$ such that\footnote{It is not strictly necessary
that $t_{k+1} = t_k + h$ here, however it is necessary for the following that
$t_{k+1} - t_k \leq h$} $t_k < t_{k+1} < t_k + T_p$, and consider that the
optimal control signal calculated at $t_k$ contains the following two portions:

\begin{equation}
  \vect{u}_i^{\star}\big(\cdot;\ \vect{e}_i(t_k)\big) = \left\{ \\
      \begin{array}{ll}
        \vect{u}_i^{\star}\big(\tau_1;\ \vect{e}_i(t_k)\big), & \tau_1 \in [t_k, t_{k+1}] \\
        \vect{u}_i^{\star}\big(\tau_2;\ \vect{e}_i(t_k)\big), & \tau_2 \in [t_{k+1}, t_k + T_p]
      \end{array}
      \right.
  \label{eq:optimal_input_portions}
\end{equation}

Both portions are admissible since the calculated optimal control input is
admissible, and hence they both conform to the input constraints.
As for the resulting predicted states, they satisfy the state constraints, and,
crucially: $\overline{\vect{e}}_i\big(t_k + T_p;\ \vect{u}_i^{\star}(\cdot), \vect{e}_i(t_k)\big) \in \mathcal{E}_i^f$.
Furthermore, according to assumption (3) of the theorem, there exists an
admissible (and certainly not guaranteed optimal) input $\vect{u}_i^f$ that
renders $\mathcal{E}_i^f$ invariant over $[t_k + T_p, t_k + T_p + h]$.

Given the above facts, we can construct an admissible input for time $t_{k+1}$
by sewing together the second portion of \eqref{eq:optimal_input_portions}
and the input $\vect{u}_i^f(\cdot)$:

\begin{equation}
  \tilde{\vect{u}}_i\big(\tau;\ \vect{e}_i(t_{k+1})\big) = \left\{ \\
      \begin{array}{ll}
        \vect{u}_i^{\star}\big(\tau;\ \vect{e}_i(t_k)\big), & \tau \in [t_{k+1}, t_k + T_p] \\
        %\vect{u}_i^f\Big(\overline{\vect{e}}_i\big(t_k + T_p;\ \vect{u}_i^{\star}, \vect{e}_i(t_k)\big)\Big), & \tau_2 \in (t_k + T_p, t_{k+1} + T_p]
        \vect{u}_i^f(\tau - t_k - T_p), & \tau \in (t_k + T_p, t_{k+1} + T_p]
      \end{array}
      \right.
\label{eq:optimal_input_t_plus_one}
\end{equation}

Applied at time $t_{k+1}$, $\tilde{\vect{u}}_i\big(\cdot;\ \vect{e}_i(t_{k+1})\big)$
is an admissible control input as a composition of admissible control inputs.

This means that feasibility of a solution to the optimization problem at time
$t_k$ implies feasibility at time $t_{k+1} > t_k$, and, thus, since at time $t=0$
a solution is assumed to be feasible, a solution to the optimal control problem
is feasible for all $t \geq 0$.\\

\textbf{Convergence analysis}
The second part of the proof involves demonstrating the convergence of the
state $\vect{e}_i$ to the terminal set $\mathcal{E}_i^f$. In order for this
to be proved, it must be shown that a proper value function decreases along
the solution trajectories starting at some initial time $t_k$. We consider the
\textit{optimal} cost $J_i^{\star}\big(\vect{e}_i(t)\big)$ as a candidate
Lyapunov function:
$$J_i^{\star}\big(\vect{e}_i(t)\big) \triangleq J_i \Big(\vect{e}_i(t), \vect{u}_i^{\star}\big(\cdot;\ \vect{e}_i(t)\big)\Big)$$
and, in particular, our goal is to show that that this cost decreases over
consecutive sampling instants $t_{k+1} = t_k + h$, i.e.
$J_i^{\star}\big(\vect{e}_i(t_{k+1})\big) - J_i^{\star}\big(\vect{e}_i(t_k)\big) \leq 0$.\\

In order not to wreak notational havoc, let us define the following terms:
\begin{gg_box}
\begin{itemize}
  \item $\vect{u}_{0,i}(\tau) \triangleq \vect{u}_i^{\star}\big(\tau;\ \vect{e}_i(t_k)\big)$
    as the \textit{optimal} input based on the measurement of state
    $\vect{e}_i(t_k)$, applied at time $\tau \geq t_k$
  \item $\vect{e}_{0,i}(\tau) \triangleq \overline{\vect{e}}_i\big(\tau;\ \vect{u}_{0,i}(\tau), \vect{e}_i(t_k)\big)$
    as the \textit{predicted} state at time $\tau \geq t_k$, that is,
    the state that results from the application of the above input
    $\vect{u}_i^{\star}\big(\tau;\ \vect{e}_i(t_k)\big)$ at time $\tau$
  \item $\vect{u}_{1,i}(\tau) \triangleq \tilde{\vect{u}}_i\big(\tau;\ \vect{e}_i(t_{k+1})\big)$
    as the \textit{feasible} input applied at $\tau \geq t_{k+1}$ (see eq. \eqref{eq:optimal_input_t_plus_one} above)
  \item $\vect{e}_{1,i}(\tau) \triangleq \overline{\vect{e}}_i\big(\tau;\ \vect{u}_{1,i}(\tau), \vect{e}_i(t_{k+1})\big)$
    as the \textit{predicted} state at time $\tau \geq t_{k+1}$, that is,
    the state that results from the application of the above input
    $\tilde{\vect{u}}_i\big(\tau;\ \vect{e}_i(t_{k+1})\big)$ at time $\tau$
\end{itemize}
\end{gg_box}

Before beginning to prove convergence, it is worth noting that while the cost
$$J_i \Big(\vect{e}_i(t), \vect{u}_i^{\star}\big(\cdot;\ \vect{e}_i(t)\big)\Big)$$
is optimal (in the sense that it is based on the optimal input, which provides
its minimum realization), a cost that is based on a plainly feasible
(and thus, without loss of generality, sub-optimal) input
$\vect{u}_i \not= \vect{u}_i^{\star}$ will result in a configuration where
\begin{equation}
J_i \Big(\vect{e}_i(t), \vect{u}_i\big(\cdot;\ \vect{e}_i(t)\big)\Big)
\geq J_i \Big(\vect{e}_i(t), \vect{u}_i^{\star}\big(\cdot;\ \vect{e}_i(t)\big)\Big)
\end{equation}

Let us now begin our investigation on the sign of the difference between the cost
that results from the application of the feasible input $\vect{u}_{1,i}$,
which we shall denote by $\overline{J}_i\big(\vect{e}_i(t_{k+1})\big)$,
and the optimal cost $J_i^{\star}\big(\vect{e}_i(t_k)\big)$, while reminding
ourselves that
$J_i \big(\overline{\vect{u}}_i (\cdot);\ \vect{e}_i(t)\big)$ $=$
$\int_{t}^{t + T_p} F_i \big(\overline{\vect{e}}_i(\tau), \overline{\vect{u}}_i (\tau)\big) d \tau$ $+$
$V_i \big(\overline{\vect{e}}_i (t + T_p)\big)$:

\begin{align}
  \overline{J}_i\big(\vect{e}_i(t_{k+1})\big) - J_i^{\star}\big(\vect{e}_i(t_k)\big) &= \\
   & V_i \big(\vect{e}_{1,i} (t_{k+1} + T_p)\big) + \int_{t_{k+1}}^{t_{k+1} + T_p} F_i \big(\vect{e}_{1,i}(\tau), \vect{u}_{1,i} (\tau)\big) d \tau \\
  -&V_i \big(\vect{e}_{0,i} (t_k + T_p)\big) - \int_{t_k}^{t_k + T_p} F_i \big(\vect{e}_{0,i}(\tau), \vect{u}_{0,i} (\tau)\big) d \tau
\end{align}

Considering that $t_k < t_{k+1} < t_k + T_p < t_{k+1} + T_p$, we break down the
two integrals above in between these intervals:

\begin{align}
  \overline{J}_i\big(\vect{e}_i(t_{k+1})\big) - J_i^{\star}\big(\vect{e}_i(t_k)\big) &= \\
    V_i \big(\vect{e}_{1,i} (t_{k+1} + T_p)\big)
    &+ \int_{t_{k+1}}^{t_k + T_p} F_i \big(\vect{e}_{1,i}(\tau), \vect{u}_{1,i} (\tau)\big) d \tau
    + \int_{t_k + T_p}^{t_{k+1} + T_p} F_i \big(\vect{e}_{1,i}(\tau), \vect{u}_{1,i} (\tau)\big) d \tau \\
    -V_i \big(\vect{e}_{0,i} (t_k + T_p)\big)
    &- \int_{t_k}^{t_{k+1}} F_i \big(\vect{e}_{0,i}(\tau), \vect{u}_{0,i} (\tau)\big) d \tau
    - \int_{t_{k+1}}^{t_k + T_p} F_i \big(\vect{e}_{0,i}(\tau), \vect{u}_{0,i} (\tau)\big) d \tau
\label{eq:convergence_4_integrals}
\end{align}

\begin{gg_box}
In between the times $t_{k+1}$ and $t_k + T_p$, the constructed feasible input
$\tilde{\vect{u}}_i\big(\cdot;\ \vect{e}_i(t_{k+1})\big)$ is equal to the optimal
input $\vect{u}_i^{\star}\big(\cdot;\ \vect{e}_i(t_k)\big)$
(see eq. \ref{eq:optimal_input_t_plus_one}), which means that
$\vect{u}_{1,i}(\cdot) = \vect{u}_{0,i}(\cdot)$ in the interval $[t_{k+1}, t_k + T_p]$.
Furthermore, this means that the predicted states according to these inputs will
be also equal in this interval: $\vect{e}_{1,i}(\cdot) = \vect{e}_{0,i}(\cdot)$.
Hence, the following equality holds over $[t_{k+1}, t_k + T_p]$:

\begin{align}
  F_i \big(\vect{e}_{1,i}(\tau), \vect{u}_{1,i} (\tau)\big) =
  F_i \big(\vect{e}_{0,i}(\tau), \vect{u}_{0,i} (\tau)\big),\ \tau \in [t_{k+1}, t_k + T_p]
\end{align}

Integrating this equality over the interval where it is valid yields

\begin{align}
  \int_{t_{k+1}}^{t_k + T_p}F_i \big(\vect{e}_{1,i}(\tau), \vect{u}_{1,i} (\tau)\big) d\tau =
  \int_{t_{k+1}}^{t_k + T_p}F_i \big(\vect{e}_{0,i}(\tau), \vect{u}_{0,i} (\tau)\big) d\tau
\end{align}

\end{gg_box}

This means that these two integrals featured in the right-hand side of eq.
\eqref{eq:convergence_4_integrals} vanish, and thus the cost difference becomes

\begin{align}
  \overline{J}_i\big(\vect{e}_i(t_{k+1})\big) - J_i^{\star}\big(\vect{e}_i(t_k)\big) &= \\
    V_i \big(\vect{e}_{1,i} (t_{k+1} + T_p)\big)
    &+\int_{t_k + T_p}^{t_{k+1} + T_p} F_i \big(\vect{e}_{1,i}(\tau), \vect{u}_{1,i} (\tau)\big) d \tau \\
    -V_i \big(\vect{e}_{0,i} (t_k + T_p)\big)
    &-\int_{t_k}^{t_{k+1}} F_i \big(\vect{e}_{0,i}(\tau), \vect{u}_{0,i} (\tau)\big) d \tau
\label{eq:convergence_2_integrals}
\end{align}

\begin{gg_box}
  We turn our attention to the first integral in the above expression, and we
  note that $(t_{k+1} + T_p) - (t_k + T_p) = t_{k+1} - t_k = h$, which is exactly the
  length of the interval where assumption (3b) of the theorem holds. Hence,
  we decide to integrate the expression found in the assumption over the
  interval $[t_{k+1} + T_p, t_k + T_p]$, for the controls and states that are
  applicable in it:
  \begin{align}
    \int_{t_k + T_p}^{t_{k+1} + T_p} \Bigg(\dfrac{\partial V_i}{\partial \vect{e}_{1,i}} g_i\big(\vect{e}_{1,i}(\tau), \vect{u}_{1,i}(\tau)\big)
    + F_i\big(\vect{e}_{1,i}(\tau), \vect{u}_{1,i}(\tau)\big)\Bigg) d\tau \leq 0 \\
    \int_{t_k + T_p}^{t_{k+1} + T_p} \dfrac{d}{d\tau} V_i\big(\vect{e}_{1,i}(\tau)\big) d \tau
    + \int_{t_k + T_p}^{t_{k+1} + T_p} F_i\big(\vect{e}_{1,i}(\tau), \vect{u}_{1,i}(\tau)\big) d\tau \leq 0 \\
    V_i\big(\vect{e}_{1,i}(t_{k+1} + T_p)\big) - V_i\big(\vect{e}_{1,i}(t_k + T_p)\big)
    + \int_{t_k + T_p}^{t_{k+1} + T_p} F_i\big(\vect{e}_{1,i}(\tau), \vect{u}_{1,i}(\tau)\big) d\tau \leq 0 \\
    V_i\big(\vect{e}_{1,i}(t_{k+1} + T_p)\big)
    + \int_{t_k + T_p}^{t_{k+1} + T_p} F_i\big(\vect{e}_{1,i}(\tau), \vect{u}_{1,i}(\tau)\big) d\tau \leq V_i\big(\vect{e}_{1,i}(t_k + T_p)\big)
  \end{align}

  The left-hand side expression is the same as the first two terms in the
  right-hand side of equality \eqref{eq:convergence_2_integrals}. We can
  introduce the third one by subtracting it from both sides of the above
  expression:
  \begin{align}
    V_i\big(\vect{e}_{1,i}(t_{k+1} + T_p)\big)
    + \int_{t_k + T_p}^{t_{k+1} + T_p} F_i\big(\vect{e}_{1,i}(\tau), \vect{u}_{1,i}(\tau)\big) d\tau
    - V_i\big(\vect{e}_{0,i}(t_k + T_p)\big) \\
    \leq V_i\big(\vect{e}_{1,i}(t_k + T_p)\big)
    - V_i\big(\vect{e}_{0,i}(t_k + T_p)\big) \\
    \leq \Big|V_i\big(\vect{e}_{1,i}(t_k + T_p)\big)
    - V_i\big(\vect{e}_{0,i}(t_k + T_p)\big)\Big|
  \end{align}
  since $x \leq |x|, \forall x \in \mathbb{R}$.

  By revisiting lemma \eqref{lemma:V_Lipschitz_e_0}, the above inequality
  becomes
  \begin{align}
    V_i\big(\vect{e}_{1,i}(t_{k+1} + T_p)\big)
    + \int_{t_k + T_p}^{t_{k+1} + T_p} F_i\big(\vect{e}_{1,i}(\tau), \vect{u}_{1,i}(\tau)\big) d\tau
    - V_i\big(\vect{e}_{0,i}(t_k + T_p)\big) \\
    \leq L_{V_i} \big\|\vect{e}_{1,i}(t_k + T_p) - \vect{e}_{0,i}(t_k + T_p)\big\|
  \end{align}

  But in the interval $[t_{k+1}, t_k + T_p]$:
  $\vect{e}_{1,i}(\cdot) = \vect{e}_{0,i}(\cdot)$, hence the right-hand side
  of the inequality equals zero
  \begin{align}
    V_i\big(\vect{e}_{1,i}(t_{k+1} + T_p)\big)
    + \int_{t_k + T_p}^{t_{k+1} + T_p} F_i\big(\vect{e}_{1,i}(\tau), \vect{u}_{1,i}(\tau)\big) d\tau
    - V_i\big(\vect{e}_{0,i}(t_k + T_p)\big) \leq 0
  \end{align}

  By subtracting the term
  $-\int_{t_k}^{t_{k+1}} F_i \big(\vect{e}_{0,i}(\tau), \vect{u}_{0,i} (\tau)\big) d \tau$
  from both sides we get
  \begin{align}
    &V_i\big(\vect{e}_{1,i}(t_{k+1} + T_p)\big)
    + \int_{t_k + T_p}^{t_{k+1} + T_p} F_i\big(\vect{e}_{1,i}(\tau), \vect{u}_{1,i}(\tau)\big) d\tau \\
    - &V_i\big(\vect{e}_{0,i}(t_k + T_p)\big)
    -\int_{t_k}^{t_{k+1}} F_i \big(\vect{e}_{0,i}(\tau), \vect{u}_{0,i} (\tau)\big) d \tau
    \leq -\int_{t_k}^{t_{k+1}} F_i \big(\vect{e}_{0,i}(\tau), \vect{u}_{0,i} (\tau)\big) d \tau
  \end{align}

  The left-hand side of the inequality is equal to the cost difference.
\end{gg_box}

Hence, the cost difference becomes
\begin{align}
  \overline{J}_i\big(\vect{e}_i(t_{k+1})\big) - J_i^{\star}\big(\vect{e}_i(t_k)\big) \leq
    -\int_{t_k}^{t_{k+1}} F_i \big(\vect{e}_{0,i}(\tau), \vect{u}_{0,i} (\tau)\big) d \tau
\end{align}

\begin{gg_box}
  $F_i$ is a positive-definite function as a sum of a positive-definite
  $\|\vect{u}_i\|^2_{\mat{R}_i}$ and a positive semi-definite function
  $\|\vect{e}_i\|^2_{\mat{Q}_i}$. If we denote by $m \geq 0$ the
  minimum eigenvalue between those of matrices $\mat{R}_i, \mat{Q}_i$, this
  means that
  $$F_i \big(\vect{e}_{0,i}(\tau), \vect{u}_{0,i} (\tau)\big) \geq m \|\vect{e}_{0,i}(\tau)\|^2$$

  By integrating the above between our interval of interest $[t_k, t_{k+1}]$ we get
  \begin{align}
    \int_{t_k}^{t_{k+1}} F_i \big(\vect{e}_{0,i}(\tau), \vect{u}_{0,i} (\tau)\big) &\geq \int_{t_k}^{t_{k+1}} m \|\vect{e}_{0,i}(\tau)\|^2 d\tau \\
    -\int_{t_k}^{t_{k+1}} F_i \big(\vect{e}_{0,i}(\tau), \vect{u}_{0,i} (\tau)\big) &\leq -m \int_{t_k}^{t_{k+1}} \|\vect{e}_{0,i}(\tau)\|^2 d\tau
  \end{align}
\end{gg_box}

Which means that the cost difference
\begin{align}
  \overline{J}_i\big(\vect{e}_i(t_{k+1})\big) - J_i^{\star}\big(\vect{e}_i(t_k)\big)
  &\leq -m \int_{t_k}^{t_{k+1}} \|\vect{e}_{0,i}(\tau)\|^2 d\tau \\
  \overline{J}_i\big(\vect{e}_i(t_{k+1})\big) - J_i^{\star}\big(\vect{e}_i(t_k)\big) &\leq 0
\end{align}

And since the cost $\overline{J}_i\big(\vect{e}_i(t_{k+1})\big)$ is, in general,
sub-optimal: $J_i^{\star}\big(\vect{e}_i(t_{k+1})\big) \leq \overline{J}_i\big(\vect{e}_i(t_{k+1})\big)$,
the Lyapunov function $J_i^{\star}(\cdot)$ is decreasing along consecutive
sampling times:
\begin{align}
 J_i^{\star}\big(\vect{e}_i(t_{k+1})\big) \leq J_i^{\star}\big(\vect{e}_i(t_k)\big)
\end{align}

Therefore, the closed-loop trajectory of $\vect{e}_i$ converges to the terminal
set $\mathcal{E}_i^f$ as $t \to \infty$. \qedsymbol
